{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image compression by using singular value decomposition\n",
    "=============================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The singular value decomposition of an arbitrary matrix\n",
    "\n",
    "What data scientists use quite often is the singular value decomposition which can be found behind linear regression and least square methods, and a useful technical tool for solving linear systems that have no unique solution (Moore-Penrose pseudoinverse), performing principal component analysis, calculating low-rank approximations. There is also a plethora of real world applications of singular value decomposition such as image compression, recommender systems, numerical weather forecast or natural language processing.\n",
    "\n",
    "In what follows we would like to introduce the concept of the singular value decomposition (SVD for short) and illustrate it by showing some applications.\n",
    "\n",
    "Let $A\\in\\mathbb{R}^{n\\times m}$ be an arbitrary (not necessarily a square) matrix. It can be complex valued as well, but in the examples we are going to deal with real matrices only. Then there exist matrices $U\\in\\mathbb{R}^{n\\times n}$, $D\\in\\mathbb{R}^{n\\times m}$ and $V\\in\\mathbb{R}^{m\\times m}$, such that $$ A = UDV^*, $$ where $U$ and $V$ are unitary matrices, that is $U^*U = UU^* = I_n$ and $V^*V=VV^*=I_m$ and $D$ is a diagonal matrix, that is $d_{ij}=0$ if $i\\ne j$. The star operation means conjugate transpose, that is $(V^*)_{ij} = \\overline V_{ji}$, but since we are dealing with real matrices now, this is the same as the transpose of the matrix. The diagonal elements in $D$ are nonnegative numbers, in decreasing order: $d_{ii} = \\sigma_i$, $\\sigma_1\\geq\\sigma_2\\geq\\ldots\\geq\\sigma_r > \\sigma_{r+1} = \\ldots = \\sigma_{\\min(n,m)} = 0$, where $r$ is the rank of the matrix $A$. These $\\sigma$ values in the diagonal of $D$ are called the singular values of $A$.\n",
    "\n",
    "Before we would go into more details, I would like to show how this decomposition can help to compress an image. We will rely on the following property of the SVD-decomposition.\n",
    "\n",
    "## Low-rank approximations of $A$\n",
    "\n",
    "Let $k\\in\\mathbb{N}$ a given natural number, where $k\\leq\\text{rank}(A)\\leq\\min\\{n, m\\}$. What we look for is a matrix $A_k$ having $\\text{rank}(A_k) = k$ which is the best approximation of $A$ among the matrices that have rank equals to $k$. To formulate the low-rank approximation problem, we would like to solve the following minimalization problem: $$ \\left|\\left| A - B \\right|\\right|_F \\to \\min !\\qquad \\mbox{ subject to }\\quad B\\in\\mathbb{R}^{n\\times m}, \\ \\text{rank}(B) = k. $$ Here $\\left|\\left| X \\right|\\right|_F$ denotes the Frobenius norm of a matrix $X$ which is the squareroot of the sum of squares of the elements of $X$.\n",
    "\n",
    "The solution of this problem can be obtained from the SVD-decomposition of $A$. If $A = UDV^*$, then we keep the first $k$ values in $D$ as is and set the subsequent singular values to zero. Let us denote the resulting diagonal matrix by $D_k$. It is easy to see that we only have to keep the first $k$ columns of $U$ and the first $k$ rows of $V$, since their other columns would be multiplied by zeros anyway. To sum up, the matrix $A_k := U_kD_kV_k^*$ is the closest matrix to $A$ (in Frobenius norm) having rank $k$, where $U_k$ and $V_k$ consist of the first $k$ columns and rows of $U$ and $V$, respectively.\n",
    "\n",
    "How can this knowledge be useful? Well, if $A$ is a large matrix, that is $n,m$ are large and $k$ is relatively small, then the information we need to store to approximate the information content stored in $A$ is much smaller. That is, we can reduce the storage space significantly and we are still able to store almost the same information that the original matrix has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrating the SVD-decomposition\n",
    "\n",
    "First I would like to illustrate the above concepts on a toy example. We define a matrix of size $4\\times 2$ having rank $2$, and we create its rank-$1$ approximation using the SVD-decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 0, 0, 2, 3, -1, -2]]).reshape((4, 2))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix $A$ has rank $2$ since its columns are linearly independent, but if $A[2,1]$ would be $4$ instead of $3$, the rank would be $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, m = A.shape\n",
    "rank_A = LA.matrix_rank(A)\n",
    "\n",
    "print(\"number of rows: {}, number of columns: {}\".format(n, m))\n",
    "print(\"the rank of A is {}\".format(rank_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in function that computes the SVD-decomposition lives in the numpy.linalg library. It returns the matrices $U$ and $V^*$ and the diagonal matrix as a vector $d$ containing the nonzero singular values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, d, V_T = LA.svd(A)\n",
    "number_of_singular_values = len(d)\n",
    "print (\"number of singular values: {}\".format(number_of_singular_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to restore $A$ from its pieces we create a diagonal matrix $D$ from the vector $d$ that has the proper size. Then the product $UDV^*$ gives back the original matrix $A$ (up to round-off errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.concatenate((np.diag(d), np.zeros((n - number_of_singular_values, m))), axis=0)\n",
    "A_restored = np.matmul(U, np.matmul(D, V_T))\n",
    "\n",
    "# A_restored = np.dot(U, np.dot(D, V_T))\n",
    "# A_restored = (U @ D) @ V_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(A, A_restored, rtol=1e-14, atol=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(A - A_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrating low-rank approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned that $A$ is \"almost\" a one-rank matrix, slightly changing one of its element would reduce its rank by $1$. So define a rank one matrix $B$ that has the same elements as $A$ with one exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1, 2, 0, 0, 2, 4, -1, -2]]).reshape((4, 2))\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_B = LA.matrix_rank(B)\n",
    "distance = LA.norm(A - B, \"fro\")\n",
    "\n",
    "print(\"the rank of B is {}\".format(rank_B))\n",
    "print(\"the Frobenius-norm of the difference matrix A-B is {}\".format(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is $B$ the matrix that is closest to $A$ among all matrices that have rank $1$? To answer this question, let's compute the rank $1$ approximation of $A$ using the SVD-decomposition. Since $k=1$, we need to keep $1$ column from $U$ and $1$ row from $V^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_1 = U[:, 0:rank_B]\n",
    "D_1 = D[0:rank_B, 0:rank_B]\n",
    "V_T_1 = V_T[0:rank_B, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1 = np.matmul(U_1, np.matmul(D_1, V_T_1))\n",
    "print(\"the best (that is the closest) rank 1 approximation of A is \\n {}\".format(A_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_A_1 = LA.norm(A - A_1, \"fro\")\n",
    "print(\"\"\"The Frobenius-norm of the difference matrix A-A_1 is {}, \n",
    "which is smaller that in our previous naive attempt.\"\"\".format(dist_from_A_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image compression using SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low-rank approximation of a matrix $A$ provides a solution for various problems. Here we would like to show how it can be used to compress an image.\n",
    "\n",
    "Images are represented in a rectangular array where each element corresponds to the grayscale value for that pixel. For colored images we have a $3$-dimensional array of size $n\\times m\\times 3$, where $n$ and $m$ represents the number of pixels vertically and horizontally, respectively, and for each pixel we store the intensity for colors red, green and blue.\n",
    "\n",
    "What we are going to do is to repeat the low-rank approximation procedure above on a larger matrix, that is, we create the low-rank approximation of a matrix that represents an image for each color separately. The resulting $3$-dimensional array will be a good approximation of the original image, as we will see soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.array(Image.open(\"images/Castle_hill.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image / 255\n",
    "row, col, _ = image.shape\n",
    "print(\"pixels in one channel: {} * {}\".format(row, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "img = fig.add_subplot(1, 1, 1)\n",
    "imgplot = plt.imshow(image)\n",
    "img.set_title(\"Castle hill, Budapest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_red = image[:, :, 0]\n",
    "image_green = image[:, :, 1]\n",
    "image_blue = image[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bytes = image.nbytes\n",
    "print(\"The space (in bytes) needed to store this image is {}\".format(original_bytes))\n",
    "# 1016 * 1600 * 3 * 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the SVD-decomposition on the $3$ matrices corresponding to the different colors separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_r, d_r, V_r = np.linalg.svd(image_red, full_matrices=True)\n",
    "U_g, d_g, V_g = np.linalg.svd(image_green, full_matrices=True)\n",
    "U_b, d_b, V_b = np.linalg.svd(image_blue, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_to_be_stored = sum([matrix.nbytes for matrix in [U_r, d_r, V_r, U_g, d_g, V_g, U_b, d_b, V_b]])\n",
    "print(\"The matrices that we store have total size (in bytes): {}\".format(bytes_to_be_stored))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we decide that the information that the image contains and represented in $1600$ columns can be represented with $k=50$ columns as well, but these $k$ columns will be taken from the decomposition matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_r_k = U_r[:, 0:k]\n",
    "V_r_k = V_r[0:k, :]\n",
    "U_g_k = U_g[:, 0:k]\n",
    "V_g_k = V_g[0:k, :]\n",
    "U_b_k = U_b[:, 0:k]\n",
    "V_b_k = V_b[0:k, :]\n",
    "\n",
    "d_r_k = d_r[0:k]\n",
    "d_g_k = d_g[0:k]\n",
    "d_b_k = d_b[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_bytes = sum([matrix.nbytes for matrix in \n",
    "                        [U_r_k, d_r_k, V_r_k, U_g_k, d_g_k, V_g_k, U_b_k, d_b_k, V_b_k]])\n",
    "print(\"The compressed matrices that we store now have total size (in bytes): {}\".format(compressed_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = compressed_bytes / original_bytes\n",
    "print(\"The compression ratio between the \\\n",
    "original image size and the total size of the compressed factors is {}\".format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct the approximate matrices for each color and merge them together. We also need to correct those pixels where the intensity value is outside of the range $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_red_approx = np.matmul(U_r_k, np.matmul(np.diag(d_r_k), V_r_k))\n",
    "image_green_approx = np.matmul(U_g_k, np.matmul(np.diag(d_g_k), V_g_k))\n",
    "image_blue_approx = np.matmul(U_b_k, np.matmul(np.diag(d_b_k), V_b_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reconstructed = np.zeros((row, col, 3))\n",
    "\n",
    "image_reconstructed[:, :, 0] = image_red_approx\n",
    "image_reconstructed[:, :, 1] = image_green_approx\n",
    "image_reconstructed[:, :, 2] = image_blue_approx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_reconstructed[image_reconstructed < 0] = 0\n",
    "image_reconstructed[image_reconstructed > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "img = fig.add_subplot(1, 1, 1)\n",
    "imgplot = plt.imshow(image_reconstructed)\n",
    "img.set_title(\"Castle hill, compressed image using the best rank-{} approximation\".format(k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different $k$'s result in different compression quality, the higher $k$ is, the closer the compressed image to the original, but increasing $k$ means larger matrixes of course. We have repeated the calculations for $k=10$ and $k=200$, we ask the reader to try the code on his/her favourite images as well. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "U_r_k = U_r[:, 0:k]\n",
    "V_r_k = V_r[0:k, :]\n",
    "U_g_k = U_g[:, 0:k]\n",
    "V_g_k = V_g[0:k, :]\n",
    "U_b_k = U_b[:, 0:k]\n",
    "V_b_k = V_b[0:k, :]\n",
    "\n",
    "d_r_k = d_r[0:k]\n",
    "d_g_k = d_g[0:k]\n",
    "d_b_k = d_b[0:k]\n",
    "\n",
    "image_red_approx = np.matmul(U_r_k, np.matmul(np.diag(d_r_k), V_r_k))\n",
    "image_green_approx = np.matmul(U_g_k, np.matmul(np.diag(d_g_k), V_g_k))\n",
    "image_blue_approx = np.matmul(U_b_k, np.matmul(np.diag(d_b_k), V_b_k))\n",
    "\n",
    "image_reconstructed = np.zeros((row, col, 3))\n",
    "image_reconstructed[:, :, 0] = image_red_approx\n",
    "image_reconstructed[:, :, 1] = image_green_approx\n",
    "image_reconstructed[:, :, 2] = image_blue_approx\n",
    "image_reconstructed[image_reconstructed < 0] = 0\n",
    "image_reconstructed[image_reconstructed > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "img = fig.add_subplot(1, 1, 1)\n",
    "imgplot = plt.imshow(image_reconstructed)\n",
    "img.set_title('Castle hill, compressed image using the best rank-{} approximation'.format(k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 200\n",
    "\n",
    "U_r_k = U_r[:, 0:k]\n",
    "V_r_k = V_r[0:k, :]\n",
    "U_g_k = U_g[:, 0:k]\n",
    "V_g_k = V_g[0:k, :]\n",
    "U_b_k = U_b[:, 0:k]\n",
    "V_b_k = V_b[0:k, :]\n",
    "\n",
    "d_r_k = d_r[0:k]\n",
    "d_g_k = d_g[0:k]\n",
    "d_b_k = d_b[0:k]\n",
    "\n",
    "image_red_approx = np.matmul(U_r_k, np.matmul(np.diag(d_r_k), V_r_k))\n",
    "image_green_approx = np.matmul(U_g_k, np.matmul(np.diag(d_g_k), V_g_k))\n",
    "image_blue_approx = np.matmul(U_b_k, np.matmul(np.diag(d_b_k), V_b_k))\n",
    "\n",
    "image_reconstructed = np.zeros((row, col, 3))\n",
    "image_reconstructed[:, :, 0] = image_red_approx\n",
    "image_reconstructed[:, :, 1] = image_green_approx\n",
    "image_reconstructed[:, :, 2] = image_blue_approx\n",
    "image_reconstructed[image_reconstructed < 0] = 0\n",
    "image_reconstructed[image_reconstructed > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "img = fig.add_subplot(1, 1, 1)\n",
    "imgplot = plt.imshow(image_reconstructed)\n",
    "img.set_title('Castle hill, compressed image using the best rank-{} approximation'.format(k))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_my_image(filename, folder=\"images\", k=50):\n",
    "    image = np.array(Image.open(folder + \"/\" + filename))\n",
    "    image = image / 255\n",
    "    row, col, _ = image.shape\n",
    "    \n",
    "    U_r, d_r, V_r = np.linalg.svd(image[:, :, 0], full_matrices=True)\n",
    "    U_g, d_g, V_g = np.linalg.svd(image[:, :, 1], full_matrices=True)\n",
    "    U_b, d_b, V_b = np.linalg.svd(image[:, :, 2], full_matrices=True)\n",
    "    \n",
    "    U_r_k = U_r[:, 0:k]\n",
    "    V_r_k = V_r[0:k, :]\n",
    "    U_g_k = U_g[:, 0:k]\n",
    "    V_g_k = V_g[0:k, :]\n",
    "    U_b_k = U_b[:, 0:k]\n",
    "    V_b_k = V_b[0:k, :]\n",
    "\n",
    "    d_r_k = d_r[0:k]\n",
    "    d_g_k = d_g[0:k]\n",
    "    d_b_k = d_b[0:k]\n",
    "\n",
    "    image_red_approx = np.matmul(U_r_k, np.matmul(np.diag(d_r_k), V_r_k))\n",
    "    image_green_approx = np.matmul(U_g_k, np.matmul(np.diag(d_g_k), V_g_k))\n",
    "    image_blue_approx = np.matmul(U_b_k, np.matmul(np.diag(d_b_k), V_b_k))\n",
    "\n",
    "    image_reconstructed = np.zeros((row, col, 3))\n",
    "    image_reconstructed[:, :, 0] = image_red_approx\n",
    "    image_reconstructed[:, :, 1] = image_green_approx\n",
    "    image_reconstructed[:, :, 2] = image_blue_approx\n",
    "    image_reconstructed[image_reconstructed < 0] = 0\n",
    "    image_reconstructed[image_reconstructed > 1] = 1\n",
    "    return image, image_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image, image_compressed = compress_my_image(filename=\"Badacsony.jpg\")\n",
    "image, image_compressed = compress_my_image(filename=\"tour_eiffel.jpg\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 20))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(image)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(image_compressed)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
